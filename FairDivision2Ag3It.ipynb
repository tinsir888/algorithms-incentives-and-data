{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvF1C/PyERZDPon08SFgKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinsir888/algorithms-incentives-and-data/blob/main/FairDivision2Ag3It.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fair allocations among 2 agent with 3 items\n",
        "\n",
        "Input of each agent is the ordinal preference profile.\n",
        "\n",
        "Consider the case that items are divisible."
      ],
      "metadata": {
        "id": "PMJGCA-K6b-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_of_item = 3\n",
        "\n",
        "class agent:\n",
        "\n",
        "  def __init__(self, true_preference, bid_preference):\n",
        "    self.bundle=[0]*num_of_item\n",
        "    self.true_preference=true_preference\n",
        "    self.bid=bid_preference\n",
        "\n",
        "  def is_truthful(self):\n",
        "    return self.true_preference == self.bid_preference\n",
        "\n",
        "  def is_sd_prefer(self,bundle1,bundle2):\n",
        "    # judge whether the agent weakly SD-prefer bundle1 to bundle2\n",
        "    cumulate1=0\n",
        "    cumulate2=0\n",
        "    for item in self.true_preference:\n",
        "      cumulate1 += bundle1[item]\n",
        "      cumulate2 += bundle2[item]\n",
        "      if cumulate1 < cumulate2:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "class fair_division_instance:\n",
        "  def __init__(self, agent1, agent2):\n",
        "    self.agent1=agent1\n",
        "    self.agent2=agent2\n",
        "    self.remain_item = [100]*num_of_item\n",
        "    self.alloc1=[0]*num_of_item\n",
        "    self.alloc2=[0]*num_of_item\n",
        "    self.is_equil=None\n",
        "\n",
        "  def not_complete(self):\n",
        "    for i in range(num_of_item):\n",
        "      if self.remain_item[i] > 0:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "  def eating_protocol(self):\n",
        "\n",
        "    i=0\n",
        "    j=0\n",
        "    #agent1_eat=self.agent1.bid[i]\n",
        "    #agent2_eat=self.agent2.bid[j]\n",
        "    while self.not_complete():\n",
        "      if self.remain_item[self.agent1.bid[i]] == 0:\n",
        "        i+=1\n",
        "        continue\n",
        "      if self.remain_item[self.agent2.bid[j]] == 0:\n",
        "        j+=1\n",
        "        continue\n",
        "\n",
        "      if self.agent1.bid[i] == self.agent2.bid[j] and self.remain_item[self.agent1.bid[i]] > 0:\n",
        "        self.alloc1[self.agent1.bid[i]] += (self.remain_item[self.agent1.bid[i]]/2)\n",
        "        self.alloc2[self.agent2.bid[j]] += (self.remain_item[self.agent2.bid[j]]/2)\n",
        "        self.remain_item[self.agent1.bid[i]] = 0\n",
        "        i+=1\n",
        "        j+=1\n",
        "      elif self.agent1.bid[i] != self.agent2.bid[j] and self.remain_item[self.agent1.bid[i]] > 0:\n",
        "        if(i<num_of_item):\n",
        "          self.alloc1[self.agent1.bid[i]] += self.remain_item[self.agent1.bid[i]]\n",
        "          self.remain_item[self.agent1.bid[i]] = 0\n",
        "          i+=1\n",
        "        if(j<num_of_item):\n",
        "          self.alloc2[self.agent2.bid[j]] += self.remain_item[self.agent2.bid[j]]\n",
        "          self.remain_item[self.agent2.bid[j]] = 0\n",
        "          j+=1\n",
        "    self.agent1.bundle=self.alloc1\n",
        "    self.agent2.bundle=self.alloc2\n",
        "  def is_equilibrium(self):\n",
        "    return True\n",
        "\n",
        "  def get_alloc(self):\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"agent1's true preference: \",self.agent1.true_preference)\n",
        "    print(\"agent2's true preference: \",self.agent2.true_preference)\n",
        "    print(\"agent1 gets: \",self.agent1.bundle)\n",
        "    print(\"agent2 gets: \",self.agent2.bundle)\n",
        "    #print(\"is equilibrium? \",self.is_equilibrium())\n",
        "    print(\"---------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "wjEKc31X7BkI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_state(true_preference1, true_preference2):\n",
        "  agent1 = agent(true_preference1,true_preference1)\n",
        "  agent2 = agent(true_preference2,true_preference2)\n",
        "  I = fair_division_instance(agent1,agent2)\n",
        "  I.eating_protocol()\n",
        "  I.get_alloc()"
      ],
      "metadata": {
        "id": "UJ1DiFqaGj2N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQmFy5vk6ZIp",
        "outputId": "7a4872b2-8366-4629-a3af-7aba69cbaa51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2)\n",
            "agent2's true preference:  (0, 1, 2)\n",
            "agent1 gets:  [50.0, 50.0, 50.0]\n",
            "agent2 gets:  [50.0, 50.0, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2)\n",
            "agent2's true preference:  (0, 2, 1)\n",
            "agent1 gets:  [50.0, 100, 0]\n",
            "agent2 gets:  [50.0, 0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2)\n",
            "agent2's true preference:  (1, 0, 2)\n",
            "agent1 gets:  [100, 0, 50.0]\n",
            "agent2 gets:  [0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2)\n",
            "agent2's true preference:  (1, 2, 0)\n",
            "agent1 gets:  [100, 0, 50.0]\n",
            "agent2 gets:  [0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2)\n",
            "agent2's true preference:  (2, 0, 1)\n",
            "agent1 gets:  [100, 50.0, 0]\n",
            "agent2 gets:  [0, 50.0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2)\n",
            "agent2's true preference:  (2, 1, 0)\n",
            "agent1 gets:  [100, 50.0, 0]\n",
            "agent2 gets:  [0, 50.0, 100]\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Generate permutations of preferences\n",
        "from itertools import permutations\n",
        "\n",
        "def solve_2agent(num_of_item):\n",
        "  # Define the elements\n",
        "  prefer1 = [i for i in range(num_of_item)]\n",
        "\n",
        "  # Generate permutations\n",
        "  prefer1_per = permutations(prefer1)\n",
        "\n",
        "  # Print the permutations\n",
        "  for per1 in prefer1_per:\n",
        "    prefer2 = [i for i in range(num_of_item)]\n",
        "    prefer2_per = permutations(prefer2)\n",
        "    for per2 in prefer2_per:\n",
        "      #print(per1, per2, type(per1))\n",
        "      check_state(per1, per2)\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "def solve_2agent_reduced(num_of_item):\n",
        "  # Define the elements\n",
        "  prefer1 = [i for i in range(num_of_item)]\n",
        "\n",
        "  # Generate permutations\n",
        "  prefer1_per = list(permutations(prefer1))\n",
        "\n",
        "  # Print the permutations\n",
        "  prefer2 = [i for i in range(num_of_item)]\n",
        "  prefer2_per = permutations(prefer2)\n",
        "\n",
        "  per1 = prefer1_per[0]\n",
        "  for per2 in prefer2_per:\n",
        "    #print(per1, per2, type(per1))\n",
        "    check_state(per1, per2)\n",
        "  #print(\"\\n\\n\\n\")\n",
        "\n",
        "num_of_item=3\n",
        "solve_2agent_reduced(num_of_item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis for cases\n",
        "\n",
        "For the scenario of 2 agents with 3 divisible goods.\n",
        "\n",
        "Assume the 3 items are $g_1,g_2,g_3$, 2 agent $1,2$.\n",
        "\n",
        "- There are $36$ cases in total, but by rotational symmetry, it can be reduced to $6$ cases.\n",
        " - For example $1:g_1\\succ g_2\\succ g_3,2:g_1\\succ g_2\\succ g_3$ is equivalent to $1:g_1\\succ g_3\\succ g_2,2:g_1\\succ g_3\\succ g_2$.\n",
        "- The $6$ cases are in the following (Fix the ordinal preference on agent 1 on $g_1\\succ g_2\\succ g_3$, we analysis agent 2 for all permutations on preference):\n",
        "\n",
        "1. agent1's true preference: $g_1\\succ g_2\\succ g_3$\n",
        "  \n",
        "  agent2's true preference:  $g_1\\succ g_2\\succ g_3$\n",
        "  \n",
        "  agent 1 gets:  $[50.0, 50.0, 50.0]$\n",
        "  \n",
        "  agent 2 gets:  $[50.0, 50.0, 50.0]$\n",
        "\n",
        "  - Best response for agent 2? **Yes**.\n",
        "    \n",
        "    Because there are no other preference prefile of player 2 inducing high sum of share of first $k$ item for $k=[3]$.\n",
        "\n",
        "2. agent1's true preference: $g_1\\succ g_2\\succ g_3$\n",
        "\n",
        "  agent2's true preference:  $g_1\\succ g_3\\succ g_2$\n",
        "  \n",
        "  agent1 gets:  $[50.0, 100, 0]$\n",
        "  \n",
        "  agent2 gets:  $[50.0, 0, 100]$\n",
        "\n",
        "  - Best response for agent 2? **Yes**.\n",
        "  \n",
        "    First observe that by eating protocol, each agent exactly gain the total share of $150$ item.\n",
        "\n",
        "    The top priority of both agents are $g_1$, thus agent 2 can't manipulate to gain higher than $50$ share of $g_1$ when agent 1 reports truthfully by putting $g_1$ on its top priority.\n",
        "  \n",
        "  - Agent 2 in case 5 has an incentive to deviate to case 2. Then it's natural to ask whether it's the best response for agent 1.\n",
        "\n",
        "    The answer is **Yes**.\n",
        "\n",
        "    - Agent 1 must put $g_1$ on top priority, otherwise it will loss the share of its favorite $g_1$.\n",
        "    - If agent $1$ switch the position of $g_2$ and $g_3$, it will loss the share of second priority $g_2$.\n",
        "\n",
        "3. agent1's true preference:  $g_1\\succ g_2\\succ g_3$\n",
        "  \n",
        "  agent2's true preference:  $g_2\\succ g_1\\succ g_3$\n",
        "  \n",
        "  agent1 gets:  $[100, 0, 50.0]$\n",
        "  \n",
        "  agent2 gets:  $[0, 100, 50.0]$\n",
        "\n",
        "  - Best response for agent 2? **Yes**.\n",
        "\n",
        "    Here any other misreport which promote share of $g_1$ will hurt the $100$ share of $g_2$.\n",
        "\n",
        "4. agent1's true preference:  $g_1\\succ g_2\\succ g_3$\n",
        "  \n",
        "  agent2's true preference:  $g_2\\succ g_3\\succ g_1$\n",
        "  \n",
        "  agent1 gets:  $[100, 0, 50.0]$\n",
        "  \n",
        "  agent2 gets:  $[0, 100, 50.0]$\n",
        "\n",
        "  - Best response for agent 2? **Yes**\n",
        "\n",
        "    Indeed, it's the best outcome for both agent: $100$ share of top priority, $50$ share of second priority.\n",
        "\n",
        "5. agent1's true preference:  $g_1\\succ g_2\\succ g_3$\n",
        "  \n",
        "  agent2's true preference:  $g_3\\succ g_1\\succ g_2$\n",
        "  \n",
        "  agent1 gets:  $[100, 50.0, 0]$\n",
        "\n",
        "  agent2 gets:  $[0, 50.0, 100]$\n",
        "\n",
        "  - Best response for agent 2? **NO!!!**\n",
        "\n",
        "    By misreporting $g_1\\succ g_3\\succ g_2$, the eating protocol allocates:\n",
        "\n",
        "    - agent 1 gets: $[50.0, 100, 0]$\n",
        "    - agent 2 gets: $[50.0, 0, 100]$\n",
        "\n",
        "    Which is strictly better off w.r.t. agent 2.\n",
        "\n",
        "6. agent1's true preference:  $g_1\\succ g_2\\succ g_3$\n",
        "  \n",
        "  agent2's true preference:  $g_3\\succ g_2\\succ g_1$\n",
        "  \n",
        "  agent1 gets:  $[100, 50.0, 0]$\n",
        "  \n",
        "  agent2 gets:  $[0, 50.0, 100]$\n",
        "\n",
        "  - Best response for agent $2$? **Yes**.\n",
        "\n",
        "    Indeed, it's the best outcome for both agent: $100$ share of top priority, $50$ share of second priority.\n",
        "\n",
        "## Graph of reporting states\n",
        "\n",
        "It is worth noting whether there are cycles in the graph $G=(V,E)$ of reporting states.\n",
        "\n",
        "There are $3!\\times3!=36$ reporting states $V$. An **directed** edge in the graph $e=(v_1,v_2)\\in E$ means there are a agent in reporting state node $v_1$ has an incentive to deviate to reporting state $v_2$.\n",
        "\n",
        "By the analysis for 6 cases above, there are no cycle in the graph."
      ],
      "metadata": {
        "id": "mHp5jGY3RKhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Agent, 4 Items"
      ],
      "metadata": {
        "id": "k1jDw4lyeHvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_item=4\n",
        "solve_2agent_reduced(num_of_item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuf9v19XeOkd",
        "outputId": "1d50542b-994e-473f-ed20-7c964d427104"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (0, 1, 2, 3)\n",
            "agent1 gets:  [50.0, 50.0, 50.0, 50.0]\n",
            "agent2 gets:  [50.0, 50.0, 50.0, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (0, 1, 3, 2)\n",
            "agent1 gets:  [50.0, 50.0, 100, 0]\n",
            "agent2 gets:  [50.0, 50.0, 0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (0, 2, 1, 3)\n",
            "agent1 gets:  [50.0, 100, 0, 50.0]\n",
            "agent2 gets:  [50.0, 0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (0, 2, 3, 1)\n",
            "agent1 gets:  [50.0, 100, 0, 50.0]\n",
            "agent2 gets:  [50.0, 0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (0, 3, 1, 2)\n",
            "agent1 gets:  [50.0, 100, 50.0, 0]\n",
            "agent2 gets:  [50.0, 0, 50.0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (0, 3, 2, 1)\n",
            "agent1 gets:  [50.0, 100, 50.0, 0]\n",
            "agent2 gets:  [50.0, 0, 50.0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (1, 0, 2, 3)\n",
            "agent1 gets:  [100, 0, 50.0, 50.0]\n",
            "agent2 gets:  [0, 100, 50.0, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (1, 0, 3, 2)\n",
            "agent1 gets:  [100, 0, 100, 0]\n",
            "agent2 gets:  [0, 100, 0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (1, 2, 0, 3)\n",
            "agent1 gets:  [100, 0, 50.0, 50.0]\n",
            "agent2 gets:  [0, 100, 50.0, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (1, 2, 3, 0)\n",
            "agent1 gets:  [100, 0, 50.0, 50.0]\n",
            "agent2 gets:  [0, 100, 50.0, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (1, 3, 0, 2)\n",
            "agent1 gets:  [100, 0, 100, 0]\n",
            "agent2 gets:  [0, 100, 0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (1, 3, 2, 0)\n",
            "agent1 gets:  [100, 0, 100, 0]\n",
            "agent2 gets:  [0, 100, 0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (2, 0, 1, 3)\n",
            "agent1 gets:  [100, 50.0, 0, 50.0]\n",
            "agent2 gets:  [0, 50.0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (2, 0, 3, 1)\n",
            "agent1 gets:  [100, 100, 0, 0]\n",
            "agent2 gets:  [0, 0, 100, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (2, 1, 0, 3)\n",
            "agent1 gets:  [100, 50.0, 0, 50.0]\n",
            "agent2 gets:  [0, 50.0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (2, 1, 3, 0)\n",
            "agent1 gets:  [100, 50.0, 0, 50.0]\n",
            "agent2 gets:  [0, 50.0, 100, 50.0]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (2, 3, 0, 1)\n",
            "agent1 gets:  [100, 100, 0, 0]\n",
            "agent2 gets:  [0, 0, 100, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (2, 3, 1, 0)\n",
            "agent1 gets:  [100, 100, 0, 0]\n",
            "agent2 gets:  [0, 0, 100, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (3, 0, 1, 2)\n",
            "agent1 gets:  [100, 50.0, 50.0, 0]\n",
            "agent2 gets:  [0, 50.0, 50.0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (3, 0, 2, 1)\n",
            "agent1 gets:  [100, 100, 0, 0]\n",
            "agent2 gets:  [0, 0, 100, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (3, 1, 0, 2)\n",
            "agent1 gets:  [100, 50.0, 50.0, 0]\n",
            "agent2 gets:  [0, 50.0, 50.0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (3, 1, 2, 0)\n",
            "agent1 gets:  [100, 50.0, 50.0, 0]\n",
            "agent2 gets:  [0, 50.0, 50.0, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (3, 2, 0, 1)\n",
            "agent1 gets:  [100, 100, 0, 0]\n",
            "agent2 gets:  [0, 0, 100, 100]\n",
            "---------------------------------------------------------\n",
            "---------------------------------------------------------\n",
            "agent1's true preference:  (0, 1, 2, 3)\n",
            "agent2's true preference:  (3, 2, 1, 0)\n",
            "agent1 gets:  [100, 100, 0, 0]\n",
            "agent2 gets:  [0, 0, 100, 100]\n",
            "---------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}